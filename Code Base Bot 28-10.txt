import os
import logging
import tempfile
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from pdfminer.high_level import extract_text
from langchain.text_splitter import RecursiveCharacterTextSplitter
from chat_utils import get_chat_model, ask_chat_model
from vectorstore_utils import create_faiss_index, retrive_relevant_docs

# ---------------- LOGGING ----------------
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ---------------- LOAD ENV ----------------
load_dotenv()
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
EURI_API_KEY = os.getenv("EURI_API_KEY")

# ---------------- SESSION STORE ----------------
user_sessions = {}  # Stores vectorstore & chat_model per user


# ---------------- HELPERS ----------------
def extract_text_from_pdf(file_path: str) -> str:
    """Extract text from a PDF file."""
    try:
        text = extract_text(file_path)
        return text if text.strip() else ""
    except Exception as e:
        logger.error(f"Error reading PDF: {e}")
        return ""


# ---------------- COMMAND HANDLERS ----------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã Hi! I'm MediChat Bot.\n\n"
        "Please upload your medical PDF document, and I‚Äôll process it automatically so you can ask questions about it."
    )


async def process_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("‚ö†Ô∏è Please upload at least one PDF first.")


# ---------------- DOCUMENT HANDLER ----------------
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    document = update.message.document

    if not document.file_name.endswith(".pdf"):
        await update.message.reply_text("‚ö†Ô∏è Please upload a valid PDF file.")
        return

    # Step 1: Download file
    file = await context.bot.get_file(document.file_id)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_pdf:
        await file.download_to_drive(temp_pdf.name)
        file_path = temp_pdf.name

    await update.message.reply_text(f"üìÑ Received: {document.file_name}")
    await update.message.reply_text("‚öôÔ∏è Processing your medical documents...")

    # Step 2: Extract text
    text = extract_text_from_pdf(file_path)
    if not text.strip():
        await update.message.reply_text("‚ö†Ô∏è Could not extract text from the document.")
        return

    # Step 3: Split text into chunks
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)
    chunks = text_splitter.split_text(text)

    # Step 4: Create FAISS index
    vectorstore = create_faiss_index(chunks)

    # Step 5: Load chat model
    chat_model = get_chat_model(EURI_API_KEY)

    # Step 6: Save session
    user_sessions[user_id] = {
        "vectorstore": vectorstore,
        "chat_model": chat_model
    }

    await update.message.reply_text("‚úÖ Documents processed successfully! You can now ask your questions.")


# ---------------- MESSAGE HANDLER ----------------
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_text = update.message.text.strip()

    # Check if user has uploaded and processed docs
    session = user_sessions.get(user_id)
    if not session or "vectorstore" not in session or "chat_model" not in session:
        await update.message.reply_text("‚ö†Ô∏è Please upload and process your documents first.")
        return

    vectorstore = session["vectorstore"]
    chat_model = session["chat_model"]

    # Step 1: Retrieve relevant docs
    await update.message.reply_chat_action("typing")
    relevant_docs = retrive_relevant_docs(vectorstore, user_text)
    if not relevant_docs:
        await update.message.reply_text("üß† No relevant information found in your documents.")
        return

    # Step 2: Combine context
    context_text = "\n\n".join([doc.page_content for doc in relevant_docs])

    # Step 3: Create prompt
    prompt = f"""
You are MediChat Pro, an intelligent assistant for medical document analysis.
Answer the question using only the context below. If the answer is not available, say so clearly.

Context:
{context_text}

Question: {user_text}

Answer:
"""

    # Step 4: Get response
    try:
        response = ask_chat_model(chat_model, prompt)
        await update.message.reply_text(response)
    except Exception as e:
        logger.error(f"Error generating response: {e}")
        await update.message.reply_text("‚ö†Ô∏è Sorry, something went wrong while generating your answer.")


# ---------------- MAIN ----------------
def main():
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("process", process_command))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    logger.info("üöÄ MediChat Bot is running...")
    app.run_polling()


if __name__ == "__main__":
    main()
